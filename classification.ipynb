{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": [],
      "mount_file_id": "1MIV_JTOlHPpgxFYDFFlrWeU2f1KAwq02",
      "authorship_tag": "ABX9TyOHCiSZcEx6WCvKN+gyCsQV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshaelza/Text-Summarization-Categorization/blob/main/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxJHb1jbv0R5"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('/content/drive/MyDrive/bbcequtrain.csv')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Ko3RcBGYxBpg",
        "outputId": "127812df-e547-4085-e9c4-52e669604db9"
      },
      "source": [
        "train"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>news_wo_punct&amp;single</th>\n",
              "      <th>Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>. trouble hit mitsubishi motor talk french ca...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>. industrial production increased december ac...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>. profit chinese computer firm lenovo stood s...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>. us german carmaker daimlerchrysler sold car...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>. libya withdrawn bn asset us asset previousl...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1490</th>\n",
              "      <td>1490</td>\n",
              "      <td>. explosion consumer technology continue dele...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491</th>\n",
              "      <td>1491</td>\n",
              "      <td>. computer help solve world difficult health ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1492</th>\n",
              "      <td>1492</td>\n",
              "      <td>. next generation dvd technology backed sony ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>1493</td>\n",
              "      <td>. first conviction piracy peer to peer networ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1494</th>\n",
              "      <td>1494</td>\n",
              "      <td>. hi tech industry starting get environmental...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1495 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                               news_wo_punct&single      Type\n",
              "0              0   . trouble hit mitsubishi motor talk french ca...  business\n",
              "1              1   . industrial production increased december ac...  business\n",
              "2              2   . profit chinese computer firm lenovo stood s...  business\n",
              "3              3   . us german carmaker daimlerchrysler sold car...  business\n",
              "4              4   . libya withdrawn bn asset us asset previousl...  business\n",
              "...          ...                                                ...       ...\n",
              "1490        1490   . explosion consumer technology continue dele...      tech\n",
              "1491        1491   . computer help solve world difficult health ...      tech\n",
              "1492        1492   . next generation dvd technology backed sony ...      tech\n",
              "1493        1493   . first conviction piracy peer to peer networ...      tech\n",
              "1494        1494   . hi tech industry starting get environmental...      tech\n",
              "\n",
              "[1495 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcrsaH4mxJD3"
      },
      "source": [
        "from sklearn import model_selection\n",
        "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(train['news_wo_punct&single'],train['Type'],test_size=0.25)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smk5Sc-5enLF"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Var8EoIuxLMX"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
        "Tfidf_vect.fit(train['news_wo_punct&single'])\n",
        "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
        "Test_X_Tfidf = Tfidf_vect.transform(Test_X)\n",
        "\n",
        "pickle.dump(Tfidf_vect, open(\"tfidf_bbc.pkl\", \"wb\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7FpqTycxRkE",
        "outputId": "f29df5ab-bf1d-4a02-c3e4-dbf11d29572b"
      },
      "source": [
        "print('TF-IDF output shape:', Train_X_Tfidf.shape)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF-IDF output shape: (1121, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceiQUhy9xdOV"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder = LabelEncoder()\n",
        "Train_Y = Encoder.fit_transform(Train_Y)\n",
        "Test_Y = Encoder.fit_transform(Test_Y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0REeuMqtxh-B",
        "outputId": "ca95c16e-c98b-477f-d2df-4273d427d07c"
      },
      "source": [
        "#svm\n",
        "\n",
        "from sklearn import  naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto').fit(Train_X_Tfidf,Train_Y)\n",
        "\n",
        "# predict the labels on validation dataset\n",
        "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
        "print(\"SVM Precision Score -> \",precision_score(predictions_SVM, Test_Y, average='micro')*100)\n",
        "print(\"SVM Recall Score -> \",recall_score(predictions_SVM, Test_Y, average='micro')*100)\n",
        "print(\"SVM f1 Score -> \",f1_score(predictions_SVM, Test_Y, average='weighted')*100)\n",
        "\n",
        "pickle.dump(SVM, open(\"svm_bbc.pkl\", \"wb\"))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM Accuracy Score ->  98.3957219251337\n",
            "SVM Precision Score ->  98.3957219251337\n",
            "SVM Recall Score ->  98.3957219251337\n",
            "SVM f1 Score ->  98.39598600382914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7verlykexr88",
        "outputId": "3aa4ca27-335b-4763-9066-2947fc608da6"
      },
      "source": [
        "#naive bayes multinomial\n",
        "\n",
        "Naive = naive_bayes.MultinomialNB().fit(Train_X_Tfidf,Train_Y)\n",
        "\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
        "print(\"Naive Bayes Precision Score -> \",precision_score(predictions_NB, Test_Y, average='micro')*100)\n",
        "print(\"Naive Bayes Recall Score -> \",recall_score(predictions_NB, Test_Y, average='micro')*100)\n",
        "print(\"Naive Bayes f1 Score -> \",f1_score(Test_Y, predictions_NB, average='weighted')*100)\n",
        "\n",
        "pickle.dump(Naive, open(\"nbm_model_bbc.pkl\", \"wb\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  97.59358288770053\n",
            "Naive Bayes Precision Score ->  97.59358288770053\n",
            "Naive Bayes Recall Score ->  97.59358288770053\n",
            "Naive Bayes f1 Score ->  97.59424099520896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BA3NcU1yLNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add96e7a-34cc-4688-fb0e-f881c1681262"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "#Naive = naive_bayes.MultinomialNB()\n",
        "B_naive = BernoulliNB().fit(Train_X_Tfidf,Train_Y)\n",
        "\n",
        "# predict the labels on validation dataset\n",
        "predictions_NB = B_naive.predict(Test_X_Tfidf)\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
        "print(\"Naive Bayes Precision Score -> \",precision_score(predictions_NB, Test_Y, average='micro')*100)\n",
        "print(\"Naive Bayes Recall Score -> \",recall_score(predictions_NB, Test_Y, average='micro')*100)\n",
        "print(\"Naive Bayes f1 Score -> \",f1_score(Test_Y, predictions_NB, average='weighted')*100)\n",
        "\n",
        "pickle.dump(B_naive, open(\"nbb_model_bbc.pkl\", \"wb\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes Accuracy Score ->  95.18716577540107\n",
            "Naive Bayes Precision Score ->  95.18716577540107\n",
            "Naive Bayes Recall Score ->  95.18716577540107\n",
            "Naive Bayes f1 Score ->  95.17828773101239\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}