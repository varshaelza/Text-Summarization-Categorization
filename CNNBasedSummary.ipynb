{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNNBasedSummary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNo18zuAGG8rgot1/HjyPeb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varshaelza/Text-Summarization-Categorization/blob/main/CNNBasedSummary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roCiKAKdZPpV"
      },
      "source": [
        "Sentence to Salience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVWdilXyYXIp"
      },
      "source": [
        "import pandas as pd\n",
        "t = pd.read_csv('/content/drive/MyDrive/BBC Dataset/LDA Summarization/LDASummariestrain.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJepYOCCYYxa"
      },
      "source": [
        "t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5Pci52UYgDG"
      },
      "source": [
        "rawData = {}\n",
        "rawSummaries = {}\n",
        "    \n",
        "# running count variable -- keeps track of the total size\n",
        "totalSentences = 0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0W1rSKsYkAK"
      },
      "source": [
        "def sep(text):\n",
        "  import nltk\n",
        "  nltk.download('punkt')\n",
        "  import re\n",
        "  text= text.replace(\"\\t\",\" \")\n",
        "  text=re.sub(r'\\.+', '.',text)\n",
        "  k=0\n",
        "  c=0\n",
        "  p=0\n",
        "  a_list=[]\n",
        "  while k<len(text):\n",
        "    if c==0 and text[k]=='.':\n",
        "      a_list.append(text[p:k+1])\n",
        "      p=k+1\n",
        "    elif c==0 and text[k]=='\"':\n",
        "      c=1\n",
        "    elif c==1 and text[k]=='\"' and text[k-1]==\".\" :\n",
        "      a_list.append(text[p:k+1])\n",
        "      p=k+1\n",
        "      c=0\n",
        "    elif c==1 and text[k]=='\"' and text[k-2]==\".\" :\n",
        "      a_list.append(text[p:k+1])\n",
        "      p=k+1\n",
        "      c=0\n",
        "    elif c==1 and text[k]=='\"':\n",
        "      c=0\n",
        "    k=k+1\n",
        "  if p<len(text)-1:\n",
        "    a_list.append(text[p:len(text)])\n",
        "  return a_list\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_MDtu7pYoKA"
      },
      "source": [
        "def spl(text):\n",
        "  t=text.split('\\n',1)\n",
        "  if len(t)!=2:\n",
        "    return \"\"\n",
        "  else :\n",
        "    return t[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhHoXRxEYxGM"
      },
      "source": [
        "j=0\n",
        "while j<len(t):\n",
        "  a=sep(t['News'][j])\n",
        "  a[0]=spl(a[0])\n",
        "  a[0]=spl(a[0])\n",
        "  if a[0]==\"\":\n",
        "    del a[0]\n",
        "  i=0\n",
        "  while i<len(a):\n",
        "    a[i] = a[i].replace('\\n',' ')\n",
        "    a[i] = a[i].replace('\\t',' ')\n",
        "    a[i]= a[i].replace(r'\\.+', \".\")\n",
        "    a[i]= a[i].replace(r'\\ +', \" \")\n",
        "    i=i+1\n",
        "\n",
        "  b=sep(t['Summary'][j])\n",
        "  b[0]=spl(b[0])\n",
        "  b[0]=spl(b[0])\n",
        "  if b[0]==\"\":\n",
        "    del b[0]\n",
        "  i=0\n",
        "  while i<len(b):\n",
        "    b[i] = b[i].replace('\\n',' ')\n",
        "    b[i] = b[i].replace('\\t',' ')\n",
        "    b[i]= b[i].replace(r'\\.+', \".\")\n",
        "    b[i]= b[i].replace(r'\\ +', \" \")\n",
        "    i=i+1\n",
        "  \n",
        "  rawData[j]=a\n",
        "  rawSummaries[j]=b\n",
        "  j=j+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXMG5asyYxyu"
      },
      "source": [
        "!pip install rouge/requirements.txt\n",
        "!pip install rouge-score\n",
        "import numpy as np\n",
        "\n",
        "def calc_rouge_scores(pred_summaries, gold_summaries, \n",
        "                                 keys=['rouge1', 'rouge2'], use_stemmer=True):\n",
        "    #Calculate rouge scores\n",
        "    from rouge_score import rouge_scorer\n",
        "    scorer = rouge_scorer.RougeScorer(keys, use_stemmer= use_stemmer)\n",
        "    n = len(pred_summaries)\n",
        "    scores = [scorer.score(pred_summaries[j], gold_summaries[j]) for \n",
        "              j in range(n)] \n",
        "              \n",
        "    #create dict\n",
        "    dict_scores={}                                                            \n",
        "    for key in keys:\n",
        "        dict_scores.update({key: {}})\n",
        "        \n",
        "    #populate dict    \n",
        "    for key in keys:\n",
        "        \n",
        "        precision_list = [scores[j][key][0] for j in range(len(scores))]\n",
        "        recall_list = [scores[j][key][1] for j in range(len(scores))]\n",
        "        f1_list = [scores[j][key][2] for j in range(len(scores))]\n",
        "\n",
        "        precision = np.mean(precision_list)\n",
        "        recall = np.mean(recall_list)\n",
        "        f1 = np.mean(f1_list)\n",
        "        \n",
        "        dict_results = {'recall': recall, 'precision': precision, 'f1': f1}\n",
        "        \n",
        "        dict_scores[key] = dict_results\n",
        "        \n",
        "    return dict_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jau-jB6zY4_m"
      },
      "source": [
        "saliency={}\n",
        "i=0\n",
        "while i<len(rawData):\n",
        "  saliency[i]=[]\n",
        "  j=0\n",
        "  while j<len(rawData[i]):\n",
        "    s=calc_rouge_scores([rawData[i][j]],[t['Summary'][i]])\n",
        "    saliency[i].append(0.5*s['rouge1']['f1']+s['rouge2']['f1']*0.5) #alpha=0.5\n",
        "    j=j+1\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwDJxU9fY5uo"
      },
      "source": [
        "tot=0;\n",
        "i=0\n",
        "while i<len(rawData):\n",
        "  tot=tot+len(rawData[i])\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cLBJXe9ZAJn"
      },
      "source": [
        "import numpy as np\n",
        "nx3output = np.zeros((tot, 3), dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME-MVOxzYx3n"
      },
      "source": [
        "i=0\n",
        "c=0\n",
        "while i<len(rawData):\n",
        "  j=0\n",
        "  while j<len(rawData[i]):\n",
        "    nx3output[c,0]=i\n",
        "    nx3output[c,1]=rawData[i][j]\n",
        "    nx3output[c,2]=saliency[i][j]\n",
        "    j=j+1\n",
        "    c=c+1\n",
        "  i=i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKHoIrtQZF7I"
      },
      "source": [
        "import pickle\n",
        "f = open(\"/content/drive/MyDrive/BBC Dataset/CNN Summarisation/sentencesToSaliency.pickle\", \"wb\")\n",
        "pickle.dump(nx3output, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVQTu6gHZJBT"
      },
      "source": [
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei8JnzyeZLTg"
      },
      "source": [
        "t.to_csv('/content/drive/MyDrive/BBC Dataset/CNN Summarisation/CNNSummariestrain')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}